{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d006b2ea-9dfe-49c7-88a9-a5a0775185fd",
   "metadata": {},
   "source": [
    "# Additional End of week Exercise - week 2\n",
    "\n",
    "Now use everything you've learned from Week 2 to build a full prototype for the technical question/answerer you built in Week 1 Exercise.\n",
    "\n",
    "This should include a Gradio UI, streaming, use of the system prompt to add expertise, and the ability to switch between models. Bonus points if you can demonstrate use of a tool!\n",
    "\n",
    "If you feel bold, see if you can add audio input so you can talk to it, and have it respond with audio. ChatGPT or Claude can help you, or email me if you have questions.\n",
    "\n",
    "I will publish a full solution here soon - unless someone beats me to it...\n",
    "\n",
    "There are so many commercial applications for this, from a language tutor, to a company onboarding solution, to a companion AI to a course (like this one!) I can't wait to see your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f68e3745-0a97-491b-a82b-5709b67809be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sounddevice\n",
      "  Downloading sounddevice-0.5.2-py3-none-macosx_10_6_x86_64.macosx_10_6_universal2.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: CFFI>=1.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from sounddevice) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from CFFI>=1.0->sounddevice) (2.22)\n",
      "Downloading sounddevice-0.5.2-py3-none-macosx_10_6_x86_64.macosx_10_6_universal2.whl (108 kB)\n",
      "Installing collected packages: sounddevice\n",
      "Successfully installed sounddevice-0.5.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sounddevice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a07e7793-b8f5-44f4-aded-5562f633271a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write as write_wav\n",
    "import whisper\n",
    "import ollama # <-- using ollama for testing gemma 3n is downloaded and on my box so i will use that too \n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52ea50f-f730-499b-b1ac-38c368a3afbb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Audio handling section - print statements are for added clarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1f3a2782-cf52-4968-89d8-5035bbed04c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "name: MacBook Air Microphone\n",
      "index: 0\n",
      "hostapi: 0\n",
      "max_input_channels: 1\n",
      "max_output_channels: 0\n",
      "default_low_input_latency: 0.0336875\n",
      "default_low_output_latency: 0.01\n",
      "default_high_input_latency: 0.043020833333333335\n",
      "default_high_output_latency: 0.1\n",
      "default_samplerate: 48000.0\n",
      "{'name': 'MacBook Air Microphone', 'index': 0, 'hostapi': 0, 'max_input_channels': 1, 'max_output_channels': 0, 'default_low_input_latency': 0.0336875, 'default_low_output_latency': 0.01, 'default_high_input_latency': 0.043020833333333335, 'default_high_output_latency': 0.1, 'default_samplerate': 48000.0}\n",
      "<class 'dict'>\n",
      "name: MacBook Air Speakers\n",
      "index: 1\n",
      "hostapi: 0\n",
      "max_input_channels: 0\n",
      "max_output_channels: 2\n",
      "default_low_input_latency: 0.01\n",
      "default_low_output_latency: 0.024416666666666666\n",
      "default_high_input_latency: 0.1\n",
      "default_high_output_latency: 0.03375\n",
      "default_samplerate: 48000.0\n",
      "{'name': 'MacBook Air Speakers', 'index': 1, 'hostapi': 0, 'max_input_channels': 0, 'max_output_channels': 2, 'default_low_input_latency': 0.01, 'default_low_output_latency': 0.024416666666666666, 'default_high_input_latency': 0.1, 'default_high_output_latency': 0.03375, 'default_samplerate': 48000.0}\n"
     ]
    }
   ],
   "source": [
    "inp_fs = 48000   # typical sample rate but we will grab device defaults \n",
    "inp_device = ''\n",
    "inp_chnl = 0\n",
    "block_size = 1024\n",
    "out_fs = 48000\n",
    "out_device = ''\n",
    "out_chnl = 0 \n",
    "recorded_frames = []\n",
    "devices = sd.query_devices(device=None, kind=None)\n",
    "for device in devices:\n",
    "    print(type(device))\n",
    "    if device['max_input_channels'] > 0 :\n",
    "        inp_device = device['name']\n",
    "        inp_fs = device['default_samplerate']\n",
    "        inp_chnl = device['max_input_channels']\n",
    "    elif device['max_output_channels'] > 0: \n",
    "        out_device = device['name']\n",
    "        out_fs = device['default_samplerate']\n",
    "        out_chnl = device['max_output_channels']\n",
    "    for k,v in zip(device.keys(), device.values()):\n",
    "        print(f'{k}: {v}')\n",
    "    print(device)\n",
    "out_fs=int(out_fs)\n",
    "sd.default.samplerate = out_fs # setting to out samplerate not sure why but feels like the right thing to do for clear output/ playback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bd03106-65be-4429-946e-ef85a326a9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def callback(indata, frames, time, status):\n",
    "    \"\"\"This function is called for every audio block.\"\"\"\n",
    "    if status:\n",
    "        print(status)\n",
    "    RECORDED_FRAMES.append(indata.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd153e97-e190-4258-ba65-c28e5126d6e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording. Press Enter to stop.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio saved to output.wav\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with sd.InputStream(samplerate=48000, channels=1, blocksize=1024, callback=callback):\n",
    "        print(\"Recording. Press Enter to stop.\")\n",
    "        input()  # Keep the stream active until Enter is pressed\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nRecording interrupted.\")\n",
    "finally:\n",
    "    if RECORDED_FRAMES:\n",
    "        # Concatenate recorded blocks and save to WAV\n",
    "        audio_data = np.concatenate(RECORDED_FRAMES, axis=0)\n",
    "        #print(type(out_fs))\n",
    "        write_wav('output.wav', 48000, audio_data)\n",
    "        print(\"Audio saved to output.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "05c4cb8a-f1fe-4555-b860-aff10526313c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#playback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10714261-09ee-4098-b915-411ef8477944",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/llms/lib/python3.11/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Grill the steaks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input #0, wav, from '/var/folders/jf/tj0cfq397d3_v0nlyqcw_05h0000gn/T/tmppo8tuc3a.wav':\n",
      "  Duration: 00:00:14.08, bitrate: 1536 kb/s\n",
      "  Stream #0:0: Audio: pcm_s32le ([1][0][0][0] / 0x0001), 48000 Hz, 1 channels, s32, 1536 kb/s\n",
      "  13.97 M-A: -0.000 fd=   0 aq=    0KB vq=    0KB sq=    0B "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "audio = AudioSegment.from_file('output.wav', format=\"wav\")\n",
    "model = whisper.load_model(\"small.en\")\n",
    "result = model.transcribe(\"output.wav\")\n",
    "print(result[\"text\"])\n",
    "play(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "295b4460-2080-46d3-99cc-d96922d032db",
   "metadata": {},
   "outputs": [],
   "source": [
    "RECORDED_FRAMES = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "79124c9a-d087-42c5-8500-943b18c58cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = whisper.load_model(\"small.en\") # i already loaded the model small.n is the small english-only version of whisper works well for my voice\n",
    "def record():\n",
    "    aud_file = 'request.wav'\n",
    "    inp_fs = 48000   # typical sample rate but we will grab device defaults \n",
    "    inp_device = ''\n",
    "    inp_chnl = 0\n",
    "    block_size = 1024\n",
    "    out_fs = 48000\n",
    "    out_device = ''\n",
    "    out_chnl = 0 \n",
    "    recorded_frames = []\n",
    "    def callback(indata, frames, time, status):\n",
    "        \"\"\"This function is called for every audio block.\"\"\"\n",
    "        if status:\n",
    "            print(status)\n",
    "        recorded_frames.append(indata.copy())\n",
    "        \n",
    "    devices = sd.query_devices(device=None, kind=None)\n",
    "    for device in devices:\n",
    "        print(type(device))\n",
    "        if device['max_input_channels'] > 0 :\n",
    "            inp_device = device['name']\n",
    "            inp_fs = device['default_samplerate']\n",
    "            inp_chnl = device['max_input_channels']\n",
    "        elif device['max_output_channels'] > 0: \n",
    "            out_device = device['name']\n",
    "            out_fs = device['default_samplerate']\n",
    "            out_chnl = device['max_output_channels']\n",
    "        for k,v in zip(device.keys(), device.values()):\n",
    "            print(f'{k}: {v}')\n",
    "        \n",
    "    out_fs=int(out_fs)\n",
    "    try:\n",
    "        with sd.InputStream(samplerate=out_fs, channels=inp_chnl, blocksize=block_size, callback=callback):\n",
    "            print(\"Recording. Press Enter to stop.\")\n",
    "            input()\n",
    "    except KeyboardInterupt:\n",
    "        print(\"recording stopped\")\n",
    "            # Concatenate recorded blocks and save to WAV\n",
    "    finally:\n",
    "        if recorded_frames:\n",
    "            audio_data = np.concatenate(recorded_frames, axis=0)\n",
    "            write_wav(aud_file, out_fs, audio_data)\n",
    "            print(f\"Audio saved to {aud_file}\")\n",
    "        else: \n",
    "            print(\"not sure why but its not working\")    \n",
    "    audio = AudioSegment.from_file(aud_file, format='wav')\n",
    "    message = model.transcribe(aud_file)\n",
    "    return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa030655-38e1-47e9-8ab1-1374032067b2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sys_prmpt = \"\"\"You are a helpful assistant. You answer any and all questions especially coding related questions.\"\"\"\n",
    "def chat_w_llm(message):\n",
    "    messages = [{'role': 'user', 'content': message}]\n",
    "    response = ''\n",
    "    stream = ollama.chat('llama3.2', messages=messages, stream=True)\n",
    "    for chunk in stream:\n",
    "        response += chunk['message']['content']\n",
    "        print(chunk['message']['content'],end='',flush=True)\n",
    "    messages.append({'role': 'assistant', 'content': response})\n",
    "    print(messages)\n",
    "    return messages\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5aa84bd5-41c2-46b9-af4b-eae5c9dd9f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_fn(message, history=[]):\n",
    "    history.append(chat_w_llm(message))\n",
    "    print(history)\n",
    "    return history[-1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "17fc4a9c-cb29-48ce-a924-bf0dd309c640",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7878\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7878/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gradio section \n",
    "\n",
    "with gr.Blocks() as ui:\n",
    "    chatbot = gr.Chatbot(type=\"messages\")\n",
    "    msg = gr.Textbox(label=\"Enter your message or record audio\") # Use a Textbox for manual input\n",
    "\n",
    "    # Add a row for the record button and audio input\n",
    "    with gr.Row():\n",
    "        record_button = gr.Button(\"Record Audio\")\n",
    "        #audio_input = gr.Audio(source=\"microphone\", type=\"filepath\") # Use filepath to get the path to the recorded audio file\n",
    "\n",
    "    clear = gr.Button(\"Clear\")\n",
    "\n",
    "    # Event listener for the record button\n",
    "    record_button.click(\n",
    "        fn=record,\n",
    "        inputs=None,\n",
    "        outputs=msg,  # Output the recording status to the message box\n",
    "    )\n",
    "    \n",
    "\n",
    "    # Event listener for sending a message (either text or based on recording)\n",
    "    msg.submit(\n",
    "        fn=chat_fn,\n",
    "        inputs=[msg,chatbot],\n",
    "        outputs=[chatbot],\n",
    "    )\n",
    "    clear.click(lambda: None, None, chatbot, queue=False) # Clear chatbot history\n",
    "\n",
    "\n",
    "ui.launch()#inbrowser=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f4a1a7a5-f5c9-4c05-b184-9d01c65535fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "name: MacBook Air Microphone\n",
      "index: 0\n",
      "hostapi: 0\n",
      "max_input_channels: 1\n",
      "max_output_channels: 0\n",
      "default_low_input_latency: 0.0336875\n",
      "default_low_output_latency: 0.01\n",
      "default_high_input_latency: 0.043020833333333335\n",
      "default_high_output_latency: 0.1\n",
      "default_samplerate: 48000.0\n",
      "<class 'dict'>\n",
      "name: MacBook Air Speakers\n",
      "index: 1\n",
      "hostapi: 0\n",
      "max_input_channels: 0\n",
      "max_output_channels: 2\n",
      "default_low_input_latency: 0.01\n",
      "default_low_output_latency: 0.024416666666666666\n",
      "default_high_input_latency: 0.1\n",
      "default_high_output_latency: 0.03375\n",
      "default_samplerate: 48000.0\n",
      "Recording. Press Enter to stop.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio saved to request.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/llms/lib/python3.11/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ' What is your name?', 'segments': [{'id': 0, 'seek': 0, 'start': 0.0, 'end': 2.0, 'text': ' What is your name?', 'tokens': [50363, 1867, 318, 534, 1438, 30, 50463], 'temperature': 0.0, 'avg_logprob': -0.4327879846096039, 'compression_ratio': 0.6923076923076923, 'no_speech_prob': 0.1053680032491684}], 'language': 'en'}\n"
     ]
    }
   ],
   "source": [
    "print(record())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5998a6e6-88c8-40d9-a6bb-6ca8518290fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Gabby\n",
      "\n",
      "Gabby, a whisper of sunshine and grace,\n",
      "With eyes that hold starlight in their space.\n",
      "A laugh like wind chimes, a melody bright,\n",
      "She dances through shadows and fills them with light.\n",
      "\n",
      "Her spirit, a garden, with blooms wild and free,\n",
      "A tapestry woven for all eyes to see.\n",
      "Kindness she offers, a gentle embrace,\n",
      "A warmth that can brighten the coldest of days.\n",
      "\n",
      "She chases her dreams with a passionate fire,\n",
      "A soul full of longing, a burning desire.\n",
      "Though moments may stumble, and shadows may fall,\n",
      "Gabby rises stronger, embracing it all.\n",
      "\n",
      "A dreamer, a thinker, a heart open wide,\n",
      "She sees the beauty the world tries to hide.\n",
      "With a smile and a spirit that shines from within,\n",
      "Gabby, a wonder, where hope can begin. \n",
      "\n",
      "So listen closely, and you'll surely hear,\n",
      "The echo of Gabby, banishing fear.\n",
      "A girl of resilience, of grace and of might,\n",
      "Gabby, a beacon, a beautiful light.\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"## Gabby\\n\\nGabby, a whisper of sunshine and grace,\\nWith eyes that hold starlight in their space.\\nA laugh like wind chimes, a melody bright,\\nShe dances through shadows and fills them with light.\\n\\nHer spirit, a garden, with blooms wild and free,\\nA tapestry woven for all eyes to see.\\nKindness she offers, a gentle embrace,\\nA warmth that can brighten the coldest of days.\\n\\nShe chases her dreams with a passionate fire,\\nA soul full of longing, a burning desire.\\nThough moments may stumble, and shadows may fall,\\nGabby rises stronger, embracing it all.\\n\\nA dreamer, a thinker, a heart open wide,\\nShe sees the beauty the world tries to hide.\\nWith a smile and a spirit that shines from within,\\nGabby, a wonder, where hope can begin. \\n\\nSo listen closely, and you'll surely hear,\\nThe echo of Gabby, banishing fear.\\nA girl of resilience, of grace and of might,\\nGabby, a beacon, a beautiful light.\\n\\n\\n\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_w_llm('please write a poem about a girl named gabby')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2700ddb7-6c56-4f89-8916-a715cb040024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I can offer insights and tips on a range of subjects. Would you mind telling me a little more about what you'd like help with?I can offer insights and tips on a range of subjects. Would you mind telling me a little more about what you'd like help with?\n"
     ]
    }
   ],
   "source": [
    "res = chat_w_llm('can you help me?')\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0835809d-ddb6-456d-bb75-f820cda136cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
